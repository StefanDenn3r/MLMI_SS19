{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6cjIFrxl4xpb"
   },
   "source": [
    "# X-Ray Landmark Detection on Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYcltK7e6r5A"
   },
   "source": [
    "## Preperation\n",
    "\n",
    "### Imports and installation of the required libraries\n",
    "\n",
    "The libraries tensorboardx and bayesian-optimization are not within the virtual environment of Google Colab, hence they have to be installed manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LI-mX3ic4zBC"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "from zipfile import ZipFile\n",
    "import os, glob\n",
    "\n",
    "! pip install tensorboardx\n",
    "! pip install bayesian-optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uo5Rut3WcSHH"
   },
   "source": [
    "### Google Colab or Zip upload\n",
    "Either upload your project to Google Drive and mount it or upload project manually as .zip file and extract it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBFA_7f5cUe0"
   },
   "outputs": [],
   "source": [
    "use_google_drive = True\n",
    "\n",
    "if use_google_drive:\n",
    "  drive.mount('gdrive')\n",
    "  % cd gdrive/My\\ Drive/MLMI_SS19\n",
    "else:\n",
    "  file = files.upload()\n",
    "  file_path = os.path.join(ROOT,list(file.keys())[0])\n",
    "  zip_file = ZipFile(file_path)\n",
    "  zip_file.extractall(ROOT)\n",
    "  zip_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wRn8HOi7rSvV"
   },
   "source": [
    "### Tensorboard and tunneling\n",
    "Install ngrok for tunneling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sc71w6qerQtF"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"ngrok-stable-linux-amd64.zip\"):\n",
    "  os.remove(\"ngrok-stable-linux-amd64.zip\")\n",
    "\n",
    "if os.path.exists(\"ngrok\"):\n",
    "  os.remove(\"ngrok\")\n",
    "  \n",
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wQ6JZY18fS4G"
   },
   "source": [
    "Start tensorboard and forward port with ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kele9MJBfAVK"
   },
   "outputs": [],
   "source": [
    "LOG_DIR = 'saved/log/'\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "\n",
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8fGr1nvVqduU"
   },
   "source": [
    "Extract ngrok url for accessing tensorboard\n",
    "\n",
    "**Attention**: Sometimes it throws an error like this:\n",
    "```\n",
    "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
    "```\n",
    "If this is the case the easiest way to solve this issue is to delete the ngrok*.zip and ngrok from the Google Drive folder and install them again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rOJxnfekqPg2"
   },
   "outputs": [],
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o8QsqbYA53MI"
   },
   "source": [
    "## Training\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1xgAd-K4Q30"
   },
   "outputs": [],
   "source": [
    "from config import CONFIG  \n",
    "from parse_config import ConfigParser\n",
    "from train import main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MsplbjDNM_eF"
   },
   "source": [
    "### Handle IOError\n",
    "\n",
    "Google Colab has problems dealing with large amount of elements within a folder. Running it until it successfully loads will ensure there won't be an error later on. See [here](https://research.google.com/colaboratory/faq.html#drive-timeout) for further details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQ1FzHqKLZU8"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "  try:\n",
    "    os.listdir('data/XRay/OnePatient/Training/ABD_LYMPH_005')\n",
    "    os.listdir('data/XRay/OnePatient/Validation/ABD_LYMPH_005')\n",
    "  except IOError:\n",
    "    print('IOError - keep running')\n",
    "  else:\n",
    "    print('succesfully accessed files')\n",
    "    break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L41jcwBrqkev"
   },
   "source": [
    "### Manual Training\n",
    "Modify parameters and train model **manually**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dc_pc9Uht4Yv"
   },
   "source": [
    "### Resume training\n",
    "By default it takes your last training run and the last model of it. \n",
    "If you want to use a specific run or a specific model you can provide it like this:\n",
    "\n",
    "```\n",
    "run_dir = \"0629_194146\"\n",
    "model_pth = \"checkpoint-epoch11.pth\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AkWxw0fjos8N"
   },
   "outputs": [],
   "source": [
    "CONFIG['arch']['args']['x_channels'] = 128\n",
    "CONFIG['arch']['args']['stage_channels'] = 512\n",
    "CONFIG['arch']['args']['num_stages'] = 5\n",
    "CONFIG['arch']['args']['dilation'] = 1\n",
    "CONFIG['arch']['args']['depthwise_separable_convolution'] = True\n",
    "\n",
    "CONFIG['data_loader']['args']['data_dir'] = \"data/XRay/OnePatient\"\n",
    "CONFIG['data_loader']['args']['batch_size'] = 1\n",
    "CONFIG['data_loader']['args']['validation_split'] = 0.2\n",
    "CONFIG['data_loader']['args']['shuffle'] = False\n",
    "CONFIG['data_loader']['args']['custom_args']['fraction_of_dataset'] = 1e-2\n",
    "CONFIG['data_loader']['args']['custom_args']['sigma'] = 80\n",
    "CONFIG['data_loader']['args']['custom_args']['sigma_reduction_factor'] = 0.995\n",
    "\n",
    "CONFIG['optimizer']['args']['lr'] = 1e-5\n",
    "\n",
    "CONFIG['trainer']['epochs'] = 1000\n",
    "CONFIG['trainer']['save_period'] = 1\n",
    "CONFIG['trainer']['early_stop'] = 50\n",
    "\n",
    "CONFIG['prediction_blur'] = 2\n",
    "\n",
    "main(ConfigParser(CONFIG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "69wusrvmt3en"
   },
   "outputs": [],
   "source": [
    "from importlib.machinery import SourceFileLoader\n",
    "\n",
    "base_saved_dir = \"saved/models/XRay\"\n",
    "\n",
    "run_dir = None\n",
    "model_pth = None\n",
    "\n",
    "for temp_run_dir in os.listdir(base_saved_dir)[::-1]:\n",
    "  if run_dir is None:\n",
    "      run_path = os.path.join(base_saved_dir, temp_run_dir)\n",
    "  else:\n",
    "    run_path = os.path.join(base_saved_dir, run_dir)\n",
    "\n",
    "  if model_pth is None:\n",
    "    model_path_list = glob.glob(f'{run_path}/checkpoint-epoch*.pth')\n",
    "    if not model_path_list:\n",
    "      continue\n",
    "    model_path = model_path_list[-1]\n",
    "    break\n",
    "  else:\n",
    "    model_path = os.path.join(run_path, model_pth)\n",
    "    break\n",
    "\n",
    "config = SourceFileLoader(\"CONFIG\", os.path.join(run_path, 'config.py')).load_module().CONFIG\n",
    "epoch = int(model_path.split('checkpoint-epoch')[-1][:-4])\n",
    "config['data_loader']['args']['custom_args']['sigma'] *= config['data_loader']['args']['custom_args']['sigma_reduction_factor']   ** epoch\n",
    "main(ConfigParser(config, model_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7vyQPQ5Q8aa"
   },
   "source": [
    "### Bayesian Optimization\n",
    "Do **automatic** Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RO9SmoL7pFaS"
   },
   "outputs": [],
   "source": [
    "from bayes_opt_train import run_bayes_opt\n",
    "\n",
    "run_bayes_opt({\n",
    "    'num_channels': (6, 8),  # {64, 128, 256}\n",
    "    'num_stacks': (2, 7),\n",
    "    'num_blocks': (1, 7),\n",
    "    'kernel_size': (1, 4),  # {3, 5, 7, 9}\n",
    "    'sigma': (0.6, 5),\n",
    "    'prediction_blur': (0.01, 1),\n",
    "    'threshold': (0.00001, 0.2),\n",
    "    'epochs': (200, 200)\n",
    "\n",
    "}, init_points=10, n_iter=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "XRay_on_colab.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
